name: SEC Scraper

on:
  # Ejecutar cada 30 minutos
  schedule:
    - cron: '*/30 * * * *'
  
  # Permitir ejecución manual desde GitHub UI
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout código
        uses: actions/checkout@v4
      
      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Instalar dependencias del sistema
        run: |
          sudo apt-get update
          sudo apt-get install -y wget ca-certificates fonts-liberation
      
      - name: Instalar dependencias Python
        run: |
          pip install --no-cache-dir -r requeriments.txt
      
      - name: Instalar Playwright
        run: |
          playwright install-deps chromium
          playwright install chromium
      
      - name: Ejecutar scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
          EMAIL_NOTIFICATIONS_ENABLED: ${{ secrets.EMAIL_NOTIFICATIONS_ENABLED }}
        run: |
          # Ejecutar scraper en background con timeout de 5 minutos
          timeout 300 python scripts/end.py &
          SCRAPER_PID=$!
          
          # Esperar a que termine o timeout
          wait $SCRAPER_PID || true
          
          echo "✅ Scraper completado"
      
      - name: Mostrar logs
        if: always()
        run: |
          echo "Scraper completado"
