name: SEC Scraper

on:
  # Ejecutar cada 30 minutos
  schedule:
    - cron: '*/30 * * * *'
  
  # Permitir ejecuciÃ³n manual desde GitHub UI
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Instalar dependencias del sistema
        run: |
          sudo apt-get update
          sudo apt-get install -y wget ca-certificates fonts-liberation
      
      - name: Instalar dependencias Python
        run: |
          pip install --no-cache-dir -r requeriments.txt
      
      - name: Instalar Playwright
        run: |
          playwright install-deps chromium
          playwright install chromium
      
      - name: Ejecutar scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
          EMAIL_NOTIFICATIONS_ENABLED: ${{ secrets.EMAIL_NOTIFICATIONS_ENABLED }}
          PYTHONUNBUFFERED: 1
        run: |
          echo "ðŸš€ Iniciando scraper..."
          
          # Ejecutar con output completo
          python -u scripts/end.py 2>&1 | tee scraper.log &
          SCRAPER_PID=$!
          
          # Esperar hasta 5 minutos
          timeout 300 tail -f scraper.log || true
          
          # Terminar proceso si sigue corriendo
          kill $SCRAPER_PID 2>/dev/null || true
          
          echo "âœ… Scraper completado"
          echo "ðŸ“‹ Ãšltimas lÃ­neas del log:"
          tail -20 scraper.log || true
      
      - name: Mostrar logs
        if: always()
        run: |
          echo "Scraper completado"
